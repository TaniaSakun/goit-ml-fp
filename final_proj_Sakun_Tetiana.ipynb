{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0693ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57b8cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Data\n",
    "train_data = pd.read_csv('./datasets/final_proj_data.csv')\n",
    "test_data = pd.read_csv('./datasets/final_proj_test.csv')\n",
    "submission = pd.read_csv('./datasets/final_proj_sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dfb923",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select numeric and categorical features\n",
    "numeric_features = train_data.select_dtypes(include=['float64', 'int64']).columns.drop('y')\n",
    "categorical_features = train_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Remove features with all missing values\n",
    "numeric_features = numeric_features[train_data[numeric_features].isnull().mean() < 1.0]\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Combine preprocessing pipelines\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfac150",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate features and target\n",
    "X = train_data.drop('y', axis=1)\n",
    "y = train_data['y']\n",
    "\n",
    "# Preprocess the data\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to balance the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define a RandomForestClassifier model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Perform grid search with 3-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='balanced_accuracy', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Best parameters and corresponding score\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Balanced Accuracy Score: {grid_search.best_score_}\")\n",
    "\n",
    "# Train the best model on the resampled training data\n",
    "best_rf_final = RandomForestClassifier(**grid_search.best_params_, random_state=42)\n",
    "best_rf_final.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Apply the adjusted threshold to validation set\n",
    "y_proba_val = best_rf_final.predict_proba(X_val)[:, 1]\n",
    "threshold = 0.3  # Adjust this threshold based on validation performance\n",
    "y_pred_adjusted_val = (y_proba_val >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab74a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the adjusted model on validation set\n",
    "balanced_acc_adjusted_rf = balanced_accuracy_score(y_val, y_pred_adjusted_val)\n",
    "conf_matrix_adjusted_rf = confusion_matrix(y_val, y_pred_adjusted_val)\n",
    "f1_adjusted_rf = f1_score(y_val, y_pred_adjusted_val)\n",
    "precision_adjusted_rf = precision_score(y_val, y_pred_adjusted_val)\n",
    "recall_adjusted_rf = recall_score(y_val, y_pred_adjusted_val)\n",
    "\n",
    "print(f\"Balanced accuracy score (Adjusted RF): {balanced_acc_adjusted_rf}\")\n",
    "print(f\"Confusion Matrix (Adjusted RF):\\n{conf_matrix_adjusted_rf}\")\n",
    "print(f\"F1 Score (Adjusted RF): {f1_adjusted_rf}\")\n",
    "print(f\"Precision (Adjusted RF): {precision_adjusted_rf}\")\n",
    "print(f\"Recall (Adjusted RF): {recall_adjusted_rf}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred_adjusted_val))\n",
    "\n",
    "# Preprocess the test set and apply the same threshold for predictions\n",
    "X_test_preprocessed = preprocessor.transform(test_data)\n",
    "y_proba_test = best_rf_final.predict_proba(X_test_preprocessed)[:, 1]\n",
    "test_predictions_adjusted = (y_proba_test >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a08f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create submission file\n",
    "submission_adjusted = pd.DataFrame({\n",
    "    'index': submission['index'],\n",
    "    'y': test_predictions_adjusted\n",
    "})\n",
    "submission_adjusted.to_csv('submission_adjusted.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
